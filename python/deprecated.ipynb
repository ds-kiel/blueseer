{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlueSeer - Training, Quantization, and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, time, copy\n",
    "\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import absl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Remove Tensorflow C-level logging and warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Force font embedding when creating figure as PDF\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_path = \"../dataset/train\"\n",
    "test_set_path = \"../dataset/test\"\n",
    "output_path = \"./constants_eval.cc\"\n",
    "\n",
    "base_path = \"./\"\n",
    "\n",
    "MODELS_DIR = os.path.join(base_path, 'models')\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_CPP = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Category Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subclasses from two different data collection periods into one common category bbreakdown\n",
    "CLASS_MAPPING = {\n",
    "        'street':'street',\n",
    "        'park':'nature',\n",
    "        'apartment':'home', \n",
    "        'supermarket':'shopping', \n",
    "        'clothing_store':'shopping', \n",
    "        'train':'transport', \n",
    "        'bus':'transport', \n",
    "        'gym':'entertainment', \n",
    "        'car':'transport', \n",
    "        'house':'home', \n",
    "        'nature':'nature', \n",
    "        'restaurant':'restaurant', \n",
    "        'cinema':'entertainment', \n",
    "        'concert':'entertainment', \n",
    "        'plane':'transport',\n",
    "        'bar':'restaurant',\n",
    "        'shopping':'shopping',\n",
    "        'transport':'transport',\n",
    "        'home':'home',\n",
    "        'office':'office',\n",
    "        'mensa':'restaurant',\n",
    "        'lecture':'university', \n",
    "    }\n",
    "\n",
    "def original_classes_to_blueseer_classes(Y_labels):\n",
    "    mapping = CLASS_MAPPING.get\n",
    "    return [mapping(label, label) for label in Y_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing collected samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all paths to .CSV files\n",
    "def find_csv_filenames(path_to_dir, suffix=\".CSV\"):\n",
    "    filenames = []\n",
    "    for sub in os.walk(path_to_dir):\n",
    "        if sub[0] != path_to_dir:\n",
    "            # find all .CSV files within the folder\n",
    "            filenames += [sub[0] + \"/\" +\n",
    "            filename for filename in os.listdir(sub[0]) if filename.endswith(suffix)]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "\n",
    "# Parse .CSV files into pandas Dataframes\n",
    "def parse_files_to_df(files):\n",
    "    dataframes = []\n",
    "    for f in files:\n",
    "        df = pd.read_csv(f)\n",
    "        dataframes.append(df)\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "\n",
    "#most common services in selected environments\n",
    "SERVICES = [\t\"0af0\", \"1802\", \"180f\", \"1812\", \"1826\", \"2222\", \"ec88\", \"fd5a\",\n",
    "    \"fd6f\", \"fdd2\", \"fddf\", \"fe03\", \"fe07\", \"fe0f\", \"fe61\", \"fe9f\",\n",
    "    \"fea0\", \"feb9\", \"febe\", \"fee0\", \"ff0d\", \"ffc0\", \"ffe0\"]\n",
    "\n",
    "# features collected that are not used when creating the dataset\n",
    "MUST_REMOVE_COLUMNS = [\" services\", \" manufacturer_data_lengths\",' time_point_1', ' time_point_2', ' time_point_3']\n",
    "\n",
    "def process_files(dataframes,\n",
    "                  without_services = False,\n",
    "                  only_labels = None,\n",
    "                  remove_columns = None,\n",
    "                  verbose=False,\n",
    "                 ):\n",
    "\n",
    "    X_datapoints = []\n",
    "    Y_labels = []\n",
    "    available_columns = dataframes[0].columns.tolist()\n",
    "    # remove label from columns\n",
    "    available_columns.remove(\"label\")\n",
    "    # remove deprecated columns that might exist in the dataset\n",
    "    for col in MUST_REMOVE_COLUMNS:\n",
    "        try:\n",
    "            available_columns.remove(col) # there must be a leading space!\n",
    "        except Exception as e:\n",
    "            #print(f\"{col} not found in dataset\")\n",
    "            pass\n",
    "    # remove any column we wish to get rid of\n",
    "    if remove_columns is not None:\n",
    "        for col in remove_columns:\n",
    "            try:\n",
    "                available_columns.remove(col) # there must be a leading space!\n",
    "            except Exception as e:\n",
    "                #print(f\"{col} not found in dataset\")\n",
    "                pass\n",
    "    # if we want to get rid of the 23most-common services, do so now\n",
    "    if without_services:\n",
    "        for serv in SERVICES:\n",
    "            available_columns.remove(f\" {serv}\") # there is always a leading space!\n",
    "\n",
    "    # for-each dataframe, add it to the dataset\n",
    "    for df in dataframes:\n",
    "        # Find label from first row\n",
    "        label = df.iloc[0][\"label\"]\n",
    "        X_datapoints.append(df[available_columns].to_numpy().flatten()) # .iloc[:num_scans-1]\n",
    "        Y_labels.append(label)\n",
    "    \n",
    "    X_datapoints = np.array(X_datapoints)\n",
    "    \n",
    "    # Update classes to DAC classes\n",
    "    Y_labels = original_classes_to_blueseer_classes(Y_labels)\n",
    "    Y_labels = np.array(Y_labels)\n",
    "    \n",
    "    # Remove entertainment class & samples from dataset\n",
    "    data_to_keep = Y_labels!='entertainment'#np.array([y!='entertainment' for y in Y_labels])\n",
    "    X_datapoints = X_datapoints[data_to_keep]\n",
    "    Y_labels = Y_labels[data_to_keep]\n",
    "    Y_labels = list(Y_labels)\n",
    "    Y_labels = np.array(Y_labels)\n",
    "    # university\n",
    "    data_to_keep = Y_labels!='university'#np.array([y!='entertainment' for y in Y_labels])\n",
    "    X_datapoints = X_datapoints[data_to_keep]\n",
    "    Y_labels = Y_labels[data_to_keep]\n",
    "    Y_labels = list(Y_labels)\n",
    "\n",
    "    # Check how many samples per environment where found\n",
    "    unique_labels = set(Y_labels)\n",
    "    if verbose:\n",
    "        print(unique_labels)\n",
    "        for lbl in unique_labels:\n",
    "            print(f\"{lbl}: {Y_labels.count(lbl)}\")\n",
    "    unique_labels = list(unique_labels)\n",
    "    \n",
    "    return X_datapoints, Y_labels, unique_labels, available_columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score normalization: find Mean and Standard deviation of the distribution\n",
    "def get_normalization_params(X):\n",
    "    X = np.array(X)\n",
    "    # Extract mean and std, per-feature\n",
    "    feature_mean = np.nanmean(X,axis=0)\n",
    "    feature_std = np.nanstd(X,axis=0)\n",
    "    return feature_mean, feature_std\n",
    "\n",
    "# X_normalized = (X - mean(X)) / STD(X)\n",
    "def normalize_data(X,\n",
    "                   Y_str,\n",
    "                   feature_mean,\n",
    "                   feature_std,\n",
    "                   labels,\n",
    "                   ):\n",
    "    X = np.array(X)\n",
    "    X = (X-feature_mean)/(feature_std+np.finfo(float).eps)\n",
    "    # Transform Y data from string to integer\n",
    "    Y = np.zeros((len(Y_str),))\n",
    "    for i in range(len(Y_str)):\n",
    "        Y[i] = labels.index(Y_str[i])\n",
    "    Y = np.array(Y,dtype=np.int8)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate C++ friendly representation of the normalization paramaters\n",
    "# The function is called when generation the C++ code of BlueSeer\n",
    "def generate_normalization_parameters_CPP(mean_list, std_list, labels):\n",
    "    mean_str = \"const float mean_list[] = {\"\n",
    "    for i in range(0, len(mean_list)):\n",
    "        if i != 0:\n",
    "            mean_str += \", \"\n",
    "        mean_str += str(mean_list[i])\n",
    "    mean_str += \"};\"\n",
    "    \n",
    "    std_str = \"const float std_list[] = {\"\n",
    "    for i in range(0, len(std_list)):\n",
    "        if i != 0:\n",
    "            std_str += \", \"\n",
    "        std_str += str(std_list[i])\n",
    "    std_str += \"};\"\n",
    "\n",
    "    labels_str = \"const char available_env[][16] = {\"\n",
    "    for i in range(0, len(labels)):\n",
    "        if i != 0:\n",
    "            labels_str += \", \"\n",
    "        labels_str += \"\\\"\"+labels[i]+\"\\\"\"\n",
    "    labels_str += \"};\"\n",
    "    return mean_str, std_str, labels_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_class_distribution(X, Y, remove_class=[]):\n",
    "    # Separate each class instance into bins\n",
    "    classes = list(np.unique(Y))\n",
    "    try:\n",
    "        classes.remove(remove_class)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    per_class_X = dict()\n",
    "    smallest_class = 999999\n",
    "    for cls in classes:\n",
    "        per_class_X[cls] = X[Y==cls]\n",
    "        smallest_class = per_class_X[cls].shape[0] if per_class_X[cls].shape[0] < smallest_class else smallest_class\n",
    "    # Shuffle data, keep an equal number of instances per class\n",
    "    for cls in classes:\n",
    "        np.random.shuffle(per_class_X[cls])\n",
    "        per_class_X[cls] = per_class_X[cls][:smallest_class]\n",
    "    # recombine into one array\n",
    "    X_new = np.concatenate([per_class_X[cls] for cls in classes], axis=0)\n",
    "    Y_new = np.array([cls for cls in classes for i in range(smallest_class)])\n",
    "    return X_new, Y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(training_path,\n",
    "                     eval_path,\n",
    "                     without_services=True,\n",
    "                     verbose=False,\n",
    "                    ):\n",
    "    if verbose:\n",
    "        print(\"Loading training data...\")\n",
    "    train_dataframes = parse_files_to_df(find_csv_filenames(training_path))\n",
    "    if verbose:\n",
    "        print(\"Loading eval data...\")\n",
    "    eval_dataframes = parse_files_to_df(find_csv_filenames(eval_path))\n",
    "    if verbose:\n",
    "        print(f\"Training set: {len(train_dataframes)} samples\")\n",
    "        print(f\"Eval set: {len(eval_dataframes)} samples\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Manipulating training data...\")\n",
    "    X_train, Y_train, labels, features = process_files(train_dataframes,\n",
    "                                                         without_services=without_services,\n",
    "                                                         verbose=verbose,\n",
    "                                                        )\n",
    "    # get per-feature normalization (mean and std)\n",
    "    feature_mean, feature_std = get_normalization_params(X=X_train)\n",
    "    # normalize dataset\n",
    "    X_train, Y_train = normalize_data(X_train,\n",
    "                                          Y_train,\n",
    "                                          feature_mean,\n",
    "                                          feature_std,\n",
    "                                          labels)\n",
    "    if verbose:\n",
    "        print(\"Manipulating eval data...\")\n",
    "    X_eval, Y_eval, _, _ = process_files(eval_dataframes,\n",
    "                                         only_labels = labels,\n",
    "                                         without_services=without_services,\n",
    "                                         verbose=verbose,\n",
    "                                        )\n",
    "    X_eval, Y_eval = normalize_data(X_eval,\n",
    "                                        Y_eval,\n",
    "                                        feature_mean,\n",
    "                                        feature_std,\n",
    "                                        labels\n",
    "                                       )\n",
    "    \n",
    "    # equalizing eval dataset\n",
    "    print(\"equalizing Eval set (all classes have the same number of samples, based on the smallest class)\")\n",
    "    X_eval,Y_eval = equalize_class_distribution(X_eval, Y_eval)\n",
    "    \n",
    "    prepared = dict()\n",
    "    prepared['training'] = (X_train, Y_train)\n",
    "    prepared['eval'] = (X_eval, Y_eval)\n",
    "    prepared['feature_mean'] = feature_mean\n",
    "    prepared['feature_std'] = feature_std\n",
    "    prepared['labels'] = labels\n",
    "    prepared['features'] = features\n",
    "    \n",
    "    return prepared\n",
    "\n",
    "# Divide training dataset into train and test sets\n",
    "def split_training_set(X_train, Y_train):\n",
    "    return X_train, Y_train, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BlueSeer Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BlueSeer_model(num_classes, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=500,input_shape=input_shape,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(1e-5),name=\"layer0_dense\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5,name=\"layer0_dropout\"))\n",
    "#     model.add(tf.keras.layers.Dense(units=500,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(1e-5),name=\"layer1_dense\"))\n",
    "#     model.add(tf.keras.layers.Dropout(0.5,name=\"layer1_dropout\"))\n",
    "    model.add(tf.keras.layers.Dense(units=num_classes,activation=\"softmax\",kernel_regularizer=tf.keras.regularizers.l2(1e-5),name=\"layer2_class_output\"))\n",
    "    return model\n",
    "\n",
    "# layer is an array containing the number of neurons per Dense layer\n",
    "# example: layers=[250,250] creates a NN with two hidden Dense layers with 250 neurons each\n",
    "# We add a dropout with p=0.5 after every layer\n",
    "def get_varying_size_BlueSeer_model(num_classes, layers):\n",
    "    model = tf.keras.Sequential()\n",
    "    for num_neurons in layers:\n",
    "        model.add(tf.keras.layers.Dense(units=num_neurons,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(1e-5)))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(units=num_classes,activation=\"softmax\",kernel_regularizer=tf.keras.regularizers.l2(1e-5)))\n",
    "    return model\n",
    "\n",
    "\n",
    "# learning Rate decay\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 4:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "def get_smallest_model(num_classes, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=num_classes,input_shape=input_shape,activation=\"softmax\",kernel_regularizer=tf.keras.regularizers.l2(1e-5),name=\"layer2_class_output\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = prepare_datasets(train_set_path, test_set_path, without_services=True, verbose=True)\n",
    "\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "feature_std = np.maximum(feature_std, 1.0)\n",
    "features = prepared['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_acc = 0.0\n",
    "for i in range(10):\n",
    "    # Create test split\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "    # Create and eval model\n",
    "    model,acc, _, _ = eval_model(X_train,\n",
    "               Y_train,\n",
    "               X_val,\n",
    "               Y_val,\n",
    "               X_eval,\n",
    "               Y_eval,\n",
    "               labels,\n",
    "               feature_mean,\n",
    "               feature_std,\n",
    "               features,\n",
    "               verbose=0,\n",
    "               quantize_model=True,\n",
    "              )\n",
    "    if acc > best_acc:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model(original_model, X_train):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(original_model)\n",
    "    # Set the optimization flag\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce integer only quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    # We keep float for input and output\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.float32\n",
    "    # Provide a representative dataset to ensure we quantize correctly\n",
    "    def representative_dataset():\n",
    "        for i in range(len(X_train)):\n",
    "            yield([np.float32(X_train[i]).reshape(1, len(X_train[0]))])\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    # Convert model\n",
    "    embedded_model = converter.convert()\n",
    "    # Temporary save the model to measure its size\n",
    "    open(\"temp_model\", \"wb\").write(embedded_model)\n",
    "    size = os.path.getsize(\"temp_model\")\n",
    "    \n",
    "    return embedded_model, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove scans and features from prepared datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_n_scans(X, num_scans=5, num_features=23):\n",
    "    assert num_scans>0 and num_scans <=5\n",
    "    return np.copy(X[:,:num_scans*num_features])\n",
    "\n",
    "def remove_features(X, features, unwanted_features):\n",
    "    X = np.copy(X)\n",
    "    features_ = features.copy()\n",
    "    for col_ft in unwanted_features:\n",
    "        try:\n",
    "            col = features_.index(col_ft)\n",
    "            X = np.delete(X,col,axis=1)\n",
    "            features_.remove(col_ft)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(features)\n",
    "            print(ft, col)\n",
    "            assert 1==0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "      # plot loss during training\n",
    "      plt.subplot(211)\n",
    "      plt.title('Loss')\n",
    "      plt.plot(history.history['loss'], label='train')\n",
    "      plt.plot(history.history['val_loss'], label='test')\n",
    "      plt.legend()\n",
    "      # plot accuracy during training\n",
    "      plt.subplot(212)\n",
    "      plt.title('Accuracy')\n",
    "      plt.plot(history.history['sparse_categorical_accuracy'], label='train')\n",
    "      plt.plot(history.history['val_sparse_categorical_accuracy'], label='test')\n",
    "      plt.legend()\n",
    "      plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model(original_model, X_train):\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(original_model)\n",
    "    # Set the optimization flag\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce integer only quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "    # We keep float for input and output\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.float32\n",
    "    # Provide a representative dataset to ensure we quantize correctly\n",
    "    def representative_dataset():\n",
    "        for i in range(len(X_train)):\n",
    "            yield([np.float32(X_train[i]).reshape(1, len(X_train[0]))])\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    # Convert model\n",
    "    embedded_model = converter.convert()\n",
    "    # Temporary save the model to measure its size\n",
    "    open(\"temp_model\", \"wb\").write(embedded_model)\n",
    "    size = os.path.getsize(\"temp_model\")\n",
    "    \n",
    "    return embedded_model, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(predictions,\n",
    "                   test_x,\n",
    "                   test_y,\n",
    "                   labels,\n",
    "                   data_columns,\n",
    "                   feature_mean,\n",
    "                   feature_std,\n",
    "                   verbose = True):\n",
    "  wrong_predictions = {label:0 for label in labels}\n",
    "  df_columns = np.array([[c+\"_\"+str(j) for c in data_columns] for j in range(0,5)]).flatten()\n",
    "  evaluation = {label:{label_: pd.DataFrame(index=df_columns, dtype=\"int\").T for label_ in labels} for label in labels}\n",
    "\n",
    "  for i in range(0, len(predictions)):\n",
    "    pred = predictions[i].flatten().tolist()\n",
    "    pred_label = \"\"\n",
    "    pred_index = pred.index( max(pred))\n",
    "    if len(labels) > pred_index:\n",
    "       pred_label = labels[pred_index] \n",
    "    true_label = labels[test_y[i]]\n",
    "\n",
    "    # which environments get wrongly classified to which environments\n",
    "    evaluation[true_label][pred_label]= evaluation[true_label][pred_label].append(pd.DataFrame([int((test_x[i][k] * feature_std[k%len(data_columns)]) + feature_mean[k%len(data_columns)]) for k in range(0, len(test_x[i]))], index=df_columns, dtype=\"int\").T, ignore_index = True)\n",
    "    if pred_label != true_label:\n",
    "        wrong_predictions[true_label] += 1\n",
    "\n",
    "  w_pred_str = \"\"\n",
    "  for l in wrong_predictions:\n",
    "    w_pred_str += l + \": \"+ str(wrong_predictions[l])+\"/\"+str(len([label_y for label_y in test_y if label_y == labels.index(l)]))+\", \"\n",
    "\n",
    "  accuracy = 1- sum(wrong_predictions.values())/len(test_y)\n",
    "\n",
    "  if verbose: \n",
    "    print(\"predicted wrong: \"+w_pred_str)\n",
    "    print(\"predicted wrong overall: \"+str(sum(wrong_predictions.values()))+\"/\"+str(len(test_y))+\" (acc: \"+str(round(accuracy*100,2))+\"%)\")\n",
    "  \n",
    "  return evaluation, accuracy\n",
    "\n",
    "\n",
    "\n",
    "def predict_tflite(tflite_model, test_x):\n",
    "  # Prepare the test data\n",
    "  x_test_ = test_x.copy()\n",
    "  x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    " \n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # Invoke the interpreter\n",
    "  y_pred = []\n",
    "  for i in range((len(x_test_))):\n",
    "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "    interpreter.invoke()\n",
    "    y_pred.append(interpreter.get_tensor(output_details[\"index\"]))\n",
    "    \n",
    "  \n",
    "  return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X_train,\n",
    "               Y_train,\n",
    "               X_test,\n",
    "               Y_test,\n",
    "               X_eval,\n",
    "               Y_eval,\n",
    "               labels,\n",
    "               feature_mean,\n",
    "               feature_std,\n",
    "               features,\n",
    "               epochs=20,\n",
    "               batch_size=32,\n",
    "               verbose=0,\n",
    "               quantize_model=True,\n",
    "               layers=None,\n",
    "              ):\n",
    "    \n",
    "    # Create Model\n",
    "    #model = BlueSeerNN(num_classes=len(labels))\n",
    "    if layers is None:\n",
    "        model = get_BlueSeer_model(len(labels),(X_train.shape[1],))\n",
    "#         model = get_smallest_model(len(labels),(X_train.shape[1],))\n",
    "    else:\n",
    "        model = get_varying_size_BlueSeer_model(len(labels),layers)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01,\n",
    "                                        decay=1e-6,\n",
    "                                        momentum=0.9)\n",
    "    # learning rate decay\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "                 )\n",
    "    # Train model\n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[lr_callback],\n",
    "                        verbose=verbose,\n",
    "                       )\n",
    "    # Plot results?\n",
    "    if verbose:\n",
    "        plot_results(history)\n",
    "\n",
    "    # Evaluate on unseen data\n",
    "    #print(\"Evaluating trained model on unseen data:\")\n",
    "    #model.evaluate(X_eval,Y_eval)\n",
    "    \n",
    "    # Test quantize aware training\n",
    "    model_q_aware = tfmot.quantization.keras.quantize_model(model)\n",
    "    model_q_aware.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "                 )\n",
    "    model_q_aware.fit(X_train,\n",
    "                        Y_train,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[lr_callback],\n",
    "                        verbose=verbose,\n",
    "                       )\n",
    "    print(\"Evaluating quantize-aware model on unseen data:\")\n",
    "    q_eval_loss, q_eval_acc = model_q_aware.evaluate(X_eval,Y_eval)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    size = 0        \n",
    "    if quantize_model:\n",
    "        # Create TFLite Model\n",
    "        model_tflite, size = convert_model(model_q_aware, X_train)\n",
    "        print(f\"Size: {size}\")\n",
    "        # Evaluate accuracy of TFLite model on eval data\n",
    "#         _, eval_accuracy_q = evaluate_preds(predict_tflite(model_tflite,np.array(copy.deepcopy(X_eval))),\n",
    "#                                             X_eval,\n",
    "#                                             Y_eval,\n",
    "#                                             labels,\n",
    "#                                             features,\n",
    "#                                             feature_mean,\n",
    "#                                             feature_std,\n",
    "#                                            )\n",
    "\n",
    "    # return confusion matrix for scan window figure\n",
    "    cm = confusion_matrix(Y_eval, np.argmax(model_q_aware.predict(X_eval),axis=1))\n",
    "    \n",
    "    return model, q_eval_acc, size, cm\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval: Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading eval data...\n",
      "Training set: 59699 samples\n",
      "Eval set: 11440 samples\n",
      "Manipulating training data...\n",
      "{'shopping', 'street', 'office', 'restaurant', 'transport', 'home', 'nature'}\n",
      "shopping: 2887\n",
      "street: 2468\n",
      "office: 14685\n",
      "restaurant: 4252\n",
      "transport: 7306\n",
      "home: 22521\n",
      "nature: 2036\n",
      "Manipulating eval data...\n",
      "{'shopping', 'street', 'office', 'restaurant', 'transport', 'home', 'nature'}\n",
      "shopping: 1233\n",
      "street: 1296\n",
      "office: 1800\n",
      "restaurant: 1648\n",
      "transport: 1427\n",
      "home: 2669\n",
      "nature: 1367\n",
      "equalizing Eval set (all classes have the same number of samples, based on the smallest class)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/yk2w7ch52gz5ql9wl0ys0vmh0000gn/T/ipykernel_97593/3800266543.py:5: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  classes.remove(remove_class)\n"
     ]
    }
   ],
   "source": [
    "prepared = prepare_datasets(train_set_path, test_set_path, without_services=True, verbose=True)\n",
    "\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "feature_std = np.maximum(feature_std, 1.0)\n",
    "features = prepared['features']\n",
    "\n",
    "# X_test = keep_n_scans(X_test, num_scans=1)\n",
    "# X_eval = keep_n_scans(X_eval, num_scans=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_eval,Y_eval = equalize_class_distribution(X_eval, Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 483us/step - loss: 0.7511 - sparse_categorical_accuracy: 0.7404\n",
      "\n",
      "\n",
      "Size: 2752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_acc = 0.0\n",
    "for i in range(15):\n",
    "    # Create test split\n",
    "    X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train, Y_train, test_size=0.1)\n",
    "    # Create and eval model\n",
    "    model,acc, _, _ = eval_model(X_train_split,\n",
    "               Y_train_split,\n",
    "               X_test,\n",
    "               Y_test,\n",
    "               X_eval,\n",
    "               Y_eval,\n",
    "               labels,\n",
    "               feature_mean,\n",
    "               feature_std,\n",
    "               features,\n",
    "               verbose=0,\n",
    "               quantize_model=True,\n",
    "              )\n",
    "    if acc > best_acc:\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 421us/step - loss: 0.6558 - sparse_categorical_accuracy: 0.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "best_model.evaluate(X_eval,Y_eval)\n",
    "export_model(best_model,\"models/blueseer_model.cc\",feature_mean,feature_std,labels,X_train)\n",
    "# export_model(best_model,\"models/shitty_model.cc\",feature_mean,feature_std,labels,X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval: Number of scans within a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SCANS = np.array([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading eval data...\n",
      "Training set: 59699 samples\n",
      "Eval set: 11440 samples\n",
      "Manipulating training data...\n",
      "{'shopping', 'street', 'office', 'restaurant', 'transport', 'home', 'nature'}\n",
      "shopping: 2887\n",
      "street: 2468\n",
      "office: 14685\n",
      "restaurant: 4252\n",
      "transport: 7306\n",
      "home: 22521\n",
      "nature: 2036\n",
      "Manipulating eval data...\n",
      "{'shopping', 'street', 'office', 'restaurant', 'transport', 'home', 'nature'}\n",
      "shopping: 1233\n",
      "street: 1296\n",
      "office: 1800\n",
      "restaurant: 1648\n",
      "transport: 1427\n",
      "home: 2669\n",
      "nature: 1367\n",
      "equalizing Eval set (all classes have the same number of samples, based on the smallest class)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/yk2w7ch52gz5ql9wl0ys0vmh0000gn/T/ipykernel_97593/3800266543.py:5: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  classes.remove(remove_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating 1 scans in input\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 556us/step - loss: 0.5427 - sparse_categorical_accuracy: 0.8186\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19432\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 558us/step - loss: 0.5545 - sparse_categorical_accuracy: 0.8174\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 573us/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8139\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 596us/step - loss: 0.5675 - sparse_categorical_accuracy: 0.8173\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 558us/step - loss: 0.5330 - sparse_categorical_accuracy: 0.8231\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 570us/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8167\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 585us/step - loss: 0.5360 - sparse_categorical_accuracy: 0.8188\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 550us/step - loss: 0.5706 - sparse_categorical_accuracy: 0.8133\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 556us/step - loss: 0.5342 - sparse_categorical_accuracy: 0.8271\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 555us/step - loss: 0.5307 - sparse_categorical_accuracy: 0.8166\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 19488\n",
      "\n",
      "\n",
      "Evaluating 2 scans in input\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 555us/step - loss: 0.6773 - sparse_categorical_accuracy: 0.7996\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 558us/step - loss: 0.6546 - sparse_categorical_accuracy: 0.8032\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 562us/step - loss: 0.5808 - sparse_categorical_accuracy: 0.8290\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 565us/step - loss: 0.6349 - sparse_categorical_accuracy: 0.8099\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 558us/step - loss: 0.6790 - sparse_categorical_accuracy: 0.7978\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 556us/step - loss: 0.5579 - sparse_categorical_accuracy: 0.8269\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 545us/step - loss: 0.6698 - sparse_categorical_accuracy: 0.8062\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 568us/step - loss: 0.6457 - sparse_categorical_accuracy: 0.8084\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 564us/step - loss: 0.6386 - sparse_categorical_accuracy: 0.8043\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 557us/step - loss: 0.6178 - sparse_categorical_accuracy: 0.8087\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31024\n",
      "\n",
      "\n",
      "Evaluating 3 scans in input\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 647us/step - loss: 0.7295 - sparse_categorical_accuracy: 0.8045\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 603us/step - loss: 0.6671 - sparse_categorical_accuracy: 0.8139\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 615us/step - loss: 0.6910 - sparse_categorical_accuracy: 0.8099\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 597us/step - loss: 0.7286 - sparse_categorical_accuracy: 0.8038\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 599us/step - loss: 0.6750 - sparse_categorical_accuracy: 0.8174\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 602us/step - loss: 0.6633 - sparse_categorical_accuracy: 0.8202\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 602us/step - loss: 0.6449 - sparse_categorical_accuracy: 0.8216\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 593us/step - loss: 0.6985 - sparse_categorical_accuracy: 0.8130\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 591us/step - loss: 0.6910 - sparse_categorical_accuracy: 0.8142\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 596us/step - loss: 0.6716 - sparse_categorical_accuracy: 0.8200\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 42520\n",
      "\n",
      "\n",
      "Evaluating 4 scans in input\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 757us/step - loss: 0.7246 - sparse_categorical_accuracy: 0.8317\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 606us/step - loss: 0.6644 - sparse_categorical_accuracy: 0.8248\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 612us/step - loss: 0.6998 - sparse_categorical_accuracy: 0.8277\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 603us/step - loss: 0.6915 - sparse_categorical_accuracy: 0.8242\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 611us/step - loss: 0.7299 - sparse_categorical_accuracy: 0.8254\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 610us/step - loss: 0.6967 - sparse_categorical_accuracy: 0.8341\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 612us/step - loss: 0.7607 - sparse_categorical_accuracy: 0.8241\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 604us/step - loss: 0.6499 - sparse_categorical_accuracy: 0.8342\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 601us/step - loss: 0.6846 - sparse_categorical_accuracy: 0.8226\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 588us/step - loss: 0.7185 - sparse_categorical_accuracy: 0.8186\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 54024\n",
      "\n",
      "\n",
      "Evaluating 5 scans in input\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 622us/step - loss: 0.8044 - sparse_categorical_accuracy: 0.8289\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 601us/step - loss: 0.7484 - sparse_categorical_accuracy: 0.8303\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 614us/step - loss: 0.7973 - sparse_categorical_accuracy: 0.8355\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 613us/step - loss: 0.7954 - sparse_categorical_accuracy: 0.8277\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 610us/step - loss: 0.7374 - sparse_categorical_accuracy: 0.8260\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 609us/step - loss: 0.7610 - sparse_categorical_accuracy: 0.8354\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 607us/step - loss: 0.7019 - sparse_categorical_accuracy: 0.8392\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 628us/step - loss: 0.8303 - sparse_categorical_accuracy: 0.8266\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 647us/step - loss: 0.7583 - sparse_categorical_accuracy: 0.8303\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 65520\n",
      "Evaluating quantize-aware model on unseen data:\n",
      "270/270 [==============================] - 0s 662us/step - loss: 0.7431 - sparse_categorical_accuracy: 0.8362\n",
      "\n",
      "\n",
      "Size: 65520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    }
   ],
   "source": [
    "accuracies_num_scans = []\n",
    "sizes_num_scans = []\n",
    "cm_num_scans = []\n",
    "\n",
    "prepared = prepare_datasets(train_set_path, test_set_path, verbose=True)\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "features = prepared['features']\n",
    "\n",
    "for num_scan in NUM_SCANS:\n",
    "    accuracies_num_scans.append([])\n",
    "    sizes_num_scans.append([])\n",
    "    cm_num_scans.append([])\n",
    "    print(f\"\\n\\nEvaluating {num_scan} scans in input\")\n",
    "    for num_model in range(10):\n",
    "        (X_train,Y_train) = prepared['training']\n",
    "        (X_eval, Y_eval) = prepared['eval']\n",
    "        # Create test split\n",
    "        X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "        X_train_split = keep_n_scans(X_train_split, num_scans=num_scan)\n",
    "        X_test = keep_n_scans(X_test, num_scans=num_scan)\n",
    "        X_eval = keep_n_scans(X_eval, num_scans=num_scan)\n",
    "        # Create and eval model\n",
    "        model, acc, size, cm = eval_model(X_train_split,\n",
    "                   Y_train_split,\n",
    "                   X_test,\n",
    "                   Y_test,\n",
    "                   X_eval,\n",
    "                   Y_eval,\n",
    "                   labels,\n",
    "                   feature_mean,\n",
    "                   feature_std,\n",
    "                   features,\n",
    "                   verbose=0,\n",
    "                   quantize_model=True,\n",
    "                   layers=[500],\n",
    "                  )\n",
    "        accuracies_num_scans[-1].append(acc)\n",
    "        sizes_num_scans[-1].append(size)\n",
    "        cm_num_scans[-1].append(cm)\n",
    "accuracies_num_scans = np.array(accuracies_num_scans)\n",
    "sizes_num_scans = np.array(sizes_num_scans)\n",
    "cm_num_scans = np.array(cm_num_scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 194.4x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(2,1, figsize=(2.7,3), sharex=True)\n",
    "ax[0].set_axisbelow(True)\n",
    "ax[1].set_axisbelow(True)\n",
    "\n",
    "x_axis = (NUM_SCANS)*0.6\n",
    "\n",
    "# Extract accuracy for dynamic environments\n",
    "if cm_num_scans is not None:\n",
    "    cm = cm_num_scans.copy()\n",
    "    cm = np.max(cm,axis=-1)/1233\n",
    "    dynenvs = np.zeros((5,10))\n",
    "    # dynamic envs\n",
    "    dynenvs[:,:] = (cm[:,:,0]+cm[:,:,1]+cm[:,:,3]+cm[:,:,4]+cm[:,:,6])/5\n",
    "\n",
    "ax[0].bar(x_axis-0.125,\n",
    "       np.nanmean(dynenvs,axis=-1)*100,\n",
    "       yerr=np.nanstd(dynenvs,axis=-1)*100,\n",
    "       width=0.2,\n",
    "       capsize=3,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#e17055'\n",
    "       )\n",
    "\n",
    "ax[0].bar(x_axis+0.125,\n",
    "       np.nanmean(accuracies_num_scans,axis=-1)*100,\n",
    "       yerr=np.nanstd(accuracies_num_scans,axis=-1)*100,\n",
    "       width=0.2,\n",
    "       capsize=3,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#0984e3'\n",
    "       )\n",
    "\n",
    "ax[0].grid(axis='y',linestyle='dashed')\n",
    "ax[0].axis([0,3,70,85])\n",
    "\n",
    "ax[0].set_yticks([70,75,80,85])\n",
    "ax[0].set_ylabel(\"Accuracy [%]\")\n",
    "\n",
    "\n",
    "\n",
    "ax[1].bar(x_axis,\n",
    "       np.nanmean(sizes_num_scans,axis=-1)/1000,\n",
    "       yerr=np.nanstd(sizes_num_scans,axis=-1)/1000,\n",
    "       width=0.3,\n",
    "       capsize=5,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#0984e3'\n",
    "       )\n",
    "\n",
    "ax[1].grid(axis='y',linestyle='dashed')\n",
    "ax[1].axis([0.3,3.3,0,80])\n",
    "\n",
    "#ax[1].set_yticks([75,77.5,80,82.5,85])\n",
    "ax[1].set_xticks(x_axis)\n",
    "ax[1].set_xticklabels(range(1,6))\n",
    "ax[1].set_xlabel(\"BLE Scans in Input\")\n",
    "\n",
    "ax[1].set_ylabel(\"Memory usage [KB]\")\n",
    "\n",
    "ax[0].legend(['Dynamic env.', 'All env.'],\n",
    "             bbox_to_anchor=(1, 1.35),\n",
    "             loc=\"upper right\",\n",
    "             ncol=2,\n",
    "             framealpha=0,\n",
    "            )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.13)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 9})\n",
    "\n",
    "plt.savefig('figures/num_scans_in_input.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm_num_scans.copy()\n",
    "cm = np.max(cm,axis=-1)/1233*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19f131d00>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.nanmean(cm,axis=1),linewidth=2)\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shopping [73.24412003 67.67234388 69.06731549 68.23195458 70.1135442 ]\n",
      "street [86.56123277 82.85482563 82.44931062 85.29602595 85.52311436]\n",
      "office [99.32684509 99.06731549 99.09975669 99.18085969 99.38361719]\n",
      "restaurant [96.33414436 96.54501217 96.87753447 97.23438767 97.35604217]\n",
      "transport [57.62368208 53.81184104 54.64720195 57.12895377 57.23438767]\n",
      "home [95.53933496 95.50689376 95.75831306 97.16139497 98.13463098]\n",
      "nature [64.16869424 71.11111111 71.79237632 74.48499594 74.36334144]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(labels)):\n",
    "    print(labels[i],np.nanmean(cm,axis=1)[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76.80454177, 87.59124088, 99.35117599, 96.10705596, 55.87996756,\n",
       "       95.53933496, 61.71938362])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shopping', 'street', 'office', 'restaurant', 'transport', 'home', 'nature']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval: Different Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_to_test = [\n",
    "    [100],\n",
    "    [250],\n",
    "    [500],\n",
    "    [250,250],\n",
    "    [500,500],\n",
    "    [250,250,250],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_arch = []\n",
    "sizes_arch = []\n",
    "\n",
    "prepared = prepare_datasets(train_set_path, test_set_path)\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "features = prepared['features']\n",
    "\n",
    "for arch in range(len(architecture_to_test)):\n",
    "    accuracies_arch.append([])\n",
    "    sizes_arch.append([])\n",
    "    print(f\"\\n\\nEvaluating architecture {architecture_to_test[arch]}\")\n",
    "    for model_it in range(10):\n",
    "        tf.keras.backend.clear_session()\n",
    "        print(f\"Model {model_it}\")\n",
    "        # Create test split\n",
    "        X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "        # Create and eval model\n",
    "        model, acc, size = eval_model(X_train_split,\n",
    "                                   Y_train_split,\n",
    "                                   X_test,\n",
    "                                   Y_test,\n",
    "                                   X_eval,\n",
    "                                   Y_eval,\n",
    "                                   labels,\n",
    "                                   feature_mean,\n",
    "                                   feature_std,\n",
    "                                   features,\n",
    "                                   verbose=0,\n",
    "                                   quantize_model=True,\n",
    "                                   layers=architecture_to_test[arch],\n",
    "                               )\n",
    "        accuracies_arch[-1].append(acc)\n",
    "        sizes_arch[-1].append(size)\n",
    "accuracies_arch = np.array(accuracies_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis[:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1, figsize=(4,4.2),sharex=True)\n",
    "ax[0].set_axisbelow(True)\n",
    "ax[1].set_axisbelow(True)\n",
    "\n",
    "tflm_extra_space = 5 #in KB\n",
    "\n",
    "x_axis = (np.arange(len(architecture_to_test)+2)+1)*0.5\n",
    "\n",
    "\n",
    "# decision tree\n",
    "ax[0].bar(x_axis[0],\n",
    "          np.nanmean([72.25,71.50,72.09,72.42,72.44,72.95,72.47,71.10,71.79,73.12]),\n",
    "          yerr=np.nanstd([72.25,71.50,72.09,72.42,72.44,72.95,72.47,71.10,71.79,73.12]),\n",
    "          width=0.3,\n",
    "          capsize=5,\n",
    "          linewidth=0.8,\n",
    "          edgecolor='black',\n",
    "          color='#55efc4'\n",
    "       )\n",
    "# random forest\n",
    "ax[0].bar(x_axis[1],\n",
    "          np.nanmean([79.42,79.78,79.34,78.72,79.59,79.24,79.67,78.89,79.37,79.52]),\n",
    "          yerr=np.nanstd([79.42,79.78,79.34,78.72,79.59,79.24,79.67,78.89,79.37,79.52]),\n",
    "          width=0.3,\n",
    "          capsize=5,\n",
    "          linewidth=0.8,\n",
    "          edgecolor='black',\n",
    "          color='#00b894',\n",
    "          hatch='/',\n",
    "       )\n",
    "\n",
    "# BlueSeer\n",
    "ax[0].bar(x_axis[2:],\n",
    "       np.nanmean(accuracies_arch,axis=-1)*100,\n",
    "       yerr=np.nanstd(accuracies_arch,axis=-1)*100,\n",
    "       width=0.3,\n",
    "       capsize=5,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#0984e3'\n",
    "       )\n",
    "# ax[0].bar(x_axis[4],\n",
    "#        np.nanmean(accuracies_arch[2])*100,\n",
    "#        yerr=np.nanstd(accuracies_arch[2])*100,\n",
    "#        width=0.3,\n",
    "#        capsize=5,\n",
    "#        linewidth=1.5,\n",
    "#        edgecolor='black',\n",
    "#        color='#74b9ff'\n",
    "#        )\n",
    "ax[0].grid(axis='y',linestyle='dashed')\n",
    "ax[0].axis([0.25,4.25,70,90])\n",
    "ax[0].set_ylabel(\"Accuracy [%]\")\n",
    "ax[0].set_yticks([70,75,80,85,90])\n",
    "\n",
    "\n",
    "# Memory usage\n",
    "\n",
    "ax[1].bar(x_axis[0],\n",
    "        15631.2/1000,\n",
    "        width=0.3,\n",
    "        capsize=5,\n",
    "        linewidth=0.8,\n",
    "        edgecolor='black',\n",
    "        color='#55efc4'\n",
    "       )\n",
    "# random forest\n",
    "ax[1].bar(x_axis[1],\n",
    "        161360.8/1000,\n",
    "        width=0.3,\n",
    "        capsize=5,\n",
    "        linewidth=0.8,\n",
    "        edgecolor='black',\n",
    "        color='#00b894',\n",
    "        hatch='/',\n",
    "       )\n",
    "\n",
    "# BlueSeer\n",
    "ax[1].bar(x_axis[2:],\n",
    "       np.nanmean(sizes_arch,axis=-1)/1000 + tflm_extra_space,\n",
    "       yerr=np.nanstd(sizes_arch,axis=-1)/1000,\n",
    "       width=0.3,\n",
    "       capsize=5,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#0984e3'\n",
    "       )\n",
    "\n",
    "\n",
    "# ax[1].bar(x_axis[4],\n",
    "#        np.nanmean(sizes_arch[2])/1000 + tflm_extra_space,\n",
    "#        yerr=np.nanstd(sizes_arch[2])/1000,\n",
    "#        width=0.3,\n",
    "#        capsize=5,\n",
    "#        linewidth=1.5,\n",
    "#        edgecolor='black',\n",
    "#        color='#74b9ff'\n",
    "#        )\n",
    "\n",
    "ax[1].set_ylabel(\"Memory\\n usage [KB]\")\n",
    "ax[0].legend(['Decision Tree', 'Random Forest', 'BlueSeer'],\n",
    "             bbox_to_anchor=(1.1, 1.5),\n",
    "             loc=\"upper right\",\n",
    "             ncol=2,\n",
    "             framealpha=0,\n",
    "            )\n",
    "ax[1].grid(axis='y',linestyle='dashed')\n",
    "ax[1].set_xticks(x_axis)\n",
    "ax[1].set_yticks([0,100,200,300])\n",
    "ax[1].set_xticklabels(['Tree','Forest','[100]','[250]',r'[500]',r'2$\\times$[250]',r'2$\\times$[500]',r'3$\\times$[250]'],\n",
    "                      rotation=25,\n",
    "                      ha='right',\n",
    "                     )\n",
    "ax[1].set_xlabel(\"Network Architecture\")\n",
    "\n",
    "# rect = matplotlib.patches.Rectangle((2.25, 0), 0.5, 100,\n",
    "#                          linewidth=2,\n",
    "#                          edgecolor='r',\n",
    "#                          facecolor='none')\n",
    "# ax[0].add_patch(rect)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=0.08)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 11})\n",
    "\n",
    "plt.savefig('figures/nn_archi_search.pdf', bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"accuracies_arch\", accuracies_arch)\n",
    "#np.save(\"sizes_arch\", sizes_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies_arch = np.load(\"numpy_data/accuracies_arch.npy\")\n",
    "# sizes_arch = np.load(\"numpy_data/sizes_arch.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(sizes_arch, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model, acc = eval_model(X_train_split,\n",
    "#                                    Y_train_split,\n",
    "#                                    X_test,\n",
    "#                                    Y_test,\n",
    "#                                    X_eval,\n",
    "#                                    Y_eval,\n",
    "#                                    labels,\n",
    "#                                    feature_mean,\n",
    "#                                    feature_std,\n",
    "#                                    features,\n",
    "#                                    verbose=1,\n",
    "#                                    quantize_model=False,\n",
    "#                                    layers=[500],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKlearn decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = prepare_datasets(train_set_path, test_set_path)\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "features = prepared['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "accuracies_dt = []\n",
    "sizes_dt = []\n",
    "\n",
    "for i in range(10):\n",
    "    (X_train,Y_train) = prepared['training']\n",
    "    (X_eval, Y_eval) = prepared['eval']\n",
    "    # Create test split\n",
    "    X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    dt_model.fit(X_train_split,Y_train_split)\n",
    "    pred = dt_model.predict(X_eval)\n",
    "    print(f\"Tree model {i}: {np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100:.2f}\")\n",
    "    accuracies_dt.append(np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100)\n",
    "    size = dt_model.tree_.node_count\n",
    "    sizes_dt.append(size)\n",
    "accuracy_dt = np.nanmean(accuracies_dt)\n",
    "print(f\"avg: {accuracy_dt:.2f}%\")\n",
    "print(f\"size: {np.nanmean(sizes_dt)*4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(dt_model, features):\n",
    "    features = [[f\"{p}_{i}\" for p in features] for i in range(5)]\n",
    "    features = [item for sublist in features for item in sublist]\n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    _ = tree.plot_tree(dt_model,\n",
    "                               feature_names=features,\n",
    "                               class_names=labels,\n",
    "                               filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_dt = []\n",
    "sizes_dt = []\n",
    "\n",
    "for i in range(10):\n",
    "    (X_train,Y_train) = prepared['training']\n",
    "    (X_eval, Y_eval) = prepared['eval']\n",
    "    # Create test split\n",
    "    X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "    dt_model = RandomForestClassifier(n_estimators=10)\n",
    "    dt_model.fit(X_train_split,Y_train_split)\n",
    "    pred = dt_model.predict(X_eval)\n",
    "    print(f\"Forest model {i}: {np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100:.2f}\")\n",
    "    accuracies_dt.append(np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100)\n",
    "    size = 0\n",
    "    for tree in dt_model.estimators_:\n",
    "        size += tree.tree_.node_count*4\n",
    "    sizes_dt.append(size)\n",
    "accuracy_dt = np.nanmean(accuracies_dt)\n",
    "print(f\"avg: {accuracy_dt:.2f}%\")\n",
    "print(f\"size: {np.nanmean(sizes_dt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(sizes_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_eval, np.argmax(best_model.predict(X_eval),axis=1))\n",
    "print(cm)\n",
    "max_v = np.sum(cm[0])\n",
    "cm = pd.DataFrame(cm, index = [lbl.capitalize() for lbl in labels],\n",
    "                  columns = [lbl.capitalize() for lbl in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (4,4))\n",
    "ax = sn.heatmap(cm/max_v*100,\n",
    "           annot=True,\n",
    "           fmt='.1f',\n",
    "           cmap=\"Blues\",\n",
    "           cbar=False,\n",
    "              )\n",
    "ax.set_ylabel(\"True Class\", fontdict= {'fontweight':'bold'})\n",
    "ax.set_xlabel(\"Predicted Class\", fontdict= {'fontweight':'bold'})\n",
    "\n",
    "plt.tight_layout()\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "\n",
    "plt.savefig('figures/confusion_matrix.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.equal(Y_eval,np.argmax(best_model.predict(X_eval),axis=1)))/len(Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(cm[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared = prepare_datasets(train_set_path, test_set_path)\n",
    "(X_train,Y_train) = prepared['training']\n",
    "(X_eval, Y_eval) = prepared['eval']\n",
    "labels = prepared['labels']\n",
    "feature_mean = prepared['feature_mean']\n",
    "feature_std = prepared['feature_std']\n",
    "features = prepared['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_feature = []\n",
    "\n",
    "\n",
    "selected_ft = [[\" device_count\",\" lost_devices\",\" new_devices\",],\n",
    "               [\" different_services\",\" services_count\",\" man_packet_len_count\", \" manufacturer_data_lengths_sum\", \" manufacturer_data_len_avg\"],\n",
    "               [\" txpower_count\",\" tx_power_avg\",\" min_txpower\",\" max_txpower\"],\n",
    "               [\" avg_received\", \" min_received\", \" max_received\"],\n",
    "               [\" avg_avg_rssi\",\" min_avg_rssi\",\" max_avg_rssi\",\" min_rssi\",\" max_rssi\",\" avg_rssi_difference\"]]\n",
    "\n",
    "\n",
    "X_train = keep_n_scans(X_train, num_scans=1)\n",
    "X_eval = keep_n_scans(X_eval, num_scans=1)\n",
    "\n",
    "# Baseline\n",
    "print(\"Baseline\")\n",
    "accuracies_feature.append([])\n",
    "for model_it in range(10):\n",
    "        # Create test split\n",
    "        X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "        # remove feature\n",
    "        # Create and eval model\n",
    "        model, acc,_ = eval_model(X_train_split,\n",
    "                                Y_train_split,\n",
    "                                X_test,\n",
    "                                Y_test,\n",
    "                                X_eval,\n",
    "                                Y_eval,\n",
    "                                labels,\n",
    "                                feature_mean,\n",
    "                                feature_std,\n",
    "                                features,\n",
    "                                verbose=0,\n",
    "                                quantize_model=False,\n",
    "                               )\n",
    "        accuracies_feature[-1].append(acc)\n",
    "\n",
    "for ft in selected_ft:\n",
    "    print(f\"Removing:{ft}\")\n",
    "    accuracies_feature.append([])\n",
    "    for model_it in range(10):\n",
    "        # Create test split\n",
    "        X_train_split, X_test, Y_train_split, Y_test = train_test_split(X_train,Y_train,test_size=0.1)\n",
    "        # remove feature\n",
    "        X_train_ = remove_features(X_train_split,features,ft)\n",
    "        X_test_ = remove_features(X_test,features,ft)\n",
    "        X_eval_ = remove_features(X_eval,features,ft)\n",
    "        # Create and eval model\n",
    "        model, acc,_ = eval_model(X_train_,\n",
    "                                Y_train_split,\n",
    "                                X_test_,\n",
    "                                Y_test,\n",
    "                                X_eval_,\n",
    "                                Y_eval,\n",
    "                                labels,\n",
    "                                feature_mean,\n",
    "                                feature_std,\n",
    "                                features,\n",
    "                                verbose=0,\n",
    "                                quantize_model=False,\n",
    "                               )\n",
    "        accuracies_feature[-1].append(acc)\n",
    "\n",
    "accuracies_feature = np.array(accuracies_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fts = ['All features',\n",
    "       'w/o Nb. Devices',\n",
    "       'w/o Nb. Services',\n",
    "       'w/o TX Power',\n",
    "       'w/o Nb. Adv. ',\n",
    "       'w/o RSS',\n",
    "      ]\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize=(6,3),) # sharex=True\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax.plot([-5,30],\n",
    "        [81.5340054]*2,\n",
    "        zorder=-1,\n",
    "        linestyle='--',\n",
    "        linewidth=2,\n",
    "        color='#0984e3'\n",
    "       )\n",
    "\n",
    "\n",
    "ax.bar(np.arange(accuracies_feature.shape[0]),\n",
    "       np.nanmean(accuracies_feature,axis=1)*100,\n",
    "       yerr=np.nanstd(accuracies_feature,axis=1)*100,\n",
    "       width=0.5,\n",
    "       capsize=5,\n",
    "       linewidth=0.8,\n",
    "       edgecolor='black',\n",
    "       color='#0984e3')\n",
    "\n",
    "\n",
    "ax.set_ylabel(\"Accuracy [%]\")\n",
    "ax.grid(axis='y',linestyle='dashed')\n",
    "ax.set_xticks(np.arange(accuracies_feature.shape[0]))\n",
    "ax.set_xticklabels(fts,\n",
    "                   rotation=35,\n",
    "                   ha='right')\n",
    "ax.set_yticks([70,75,80,85,90])\n",
    "ax.axis([-0.5,5.5,70,90])\n",
    "\n",
    "plt.tight_layout()\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "\n",
    "#plt.savefig('figures/feature_analysis.pdf', bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(accuracies_feature,axis=1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"acc_feature_analysis\", accuracies_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies_feature = np.load(\"numpy_data/acc_feature_analysis.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_features = np.array([0,1,2,3,4,5,6,7,14,15,22])\n",
    "for i in interesting_features:\n",
    "    print(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "dd = SelectKBest(f_classif, k=50)\n",
    "X_new = dd.fit_transform(X_train, Y_train)\n",
    "Xe_new = dd.transform(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in dd.get_support(True):\n",
    "    scan_idx = idx//23\n",
    "    ft = idx%23\n",
    "    print(f\"{features[ft]}, scan {scan_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1, d2 = f_classif(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d1[:23])\n",
    "i = 0\n",
    "for ft in features:\n",
    "    print(f\"{i}: {ft}, {d1[i]}\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_new,Y_train)\n",
    "pred = dt_model.predict(Xe_new)\n",
    "print(f\"Tree model {i}: {np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100:.2f}\")\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,Y_train)\n",
    "pred = dt_model.predict(X_eval)\n",
    "print(f\"Tree model {i}: {np.sum(np.equal(pred,Y_eval))/pred.shape[0]*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = [[32,3,0,2,3,61,16,5,246,238,116,15,12,1,31,-70,-88,-33,-91,-32,6,7425,63618,\n",
    "         35,0,4,2,5,56,25,5,246,230,116,15,11,1,27,-71,-89,-33,-89,-32,6,6042,58696,\n",
    "         31,1,3,2,5,56,12,5,246,226,134,15,12,1,31,-69,-87,-34,-87,-33,6,8416,68209,\n",
    "         29,2,4,3,6,64,23,5,246,224,116,15,13,1,32,-69,-90,-34,-90,-32,7,9586,71786,\n",
    "         27,6,2,2,3,54,21,5,246,231,116,15,14,1,30,-67,-85,-34,-86,-34,6,9894,76912,]]\n",
    "inpt,_ = normalize_data(inpt,[\"office\"],feature_mean,feature_std,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.predict(inpt)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ble_environment_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
